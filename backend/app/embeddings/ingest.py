"""
PDF í´ë”ë¥¼ ëŒë©´ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ â†’ LangChain ë¬¸ì„œ ì²­í¬ â†’ Pinecone ì—…ë¡œë“œ
ë©”íƒ€ë°ì´í„° êµ¬ì¡°í™” ì§€ì› (ë³´í—˜ ì•½ê´€ ì „ìš©)
"""
import json
import argparse
import os
import glob
import pinecone
from datetime import datetime
from typing import Dict, Any, List, Optional

from langchain.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.vectorstores import Pinecone

# ëª…ë ¹í–‰ ì¸ì íŒŒì‹±
parser = argparse.ArgumentParser(description='PDF ë¬¸ì„œë¥¼ Pineconeì— ì—…ë¡œë“œí•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸')
parser.add_argument('--metadata', type=str, help='JSON í˜•ì‹ì˜ ë©”íƒ€ë°ì´í„° íŒŒì¼ ê²½ë¡œ')
parser.add_argument('--pdf_dir', type=str, default='pdf', help='PDF íŒŒì¼ì´ ìˆëŠ” ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: pdf)')
args = parser.parse_args()

# Pinecone ì´ˆê¸°í™”
pinecone.init(api_key=os.getenv("PINECONE_API_KEY"), environment=os.getenv("PINECONE_ENV"))
index = pinecone.Index(os.getenv("PINECONE_INDEX"))

# OpenAI ì„ë² ë”© ì´ˆê¸°í™”
emb = OpenAIEmbeddings()

# Pinecone ë²¡í„°ìŠ¤í† ì–´ ì´ˆê¸°í™”
vectorstore = Pinecone.from_existing_index(index_name=os.getenv("PINECONE_INDEX"), embedding=emb)

# í…ìŠ¤íŠ¸ ìŠ¤í”Œë¦¬í„° ì„¤ì •
splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=150)

# ë©”íƒ€ë°ì´í„° ë¡œë“œ (ìˆëŠ” ê²½ìš°)
metadata_mapping = {}
if args.metadata and os.path.exists(args.metadata):
    try:
        with open(args.metadata, 'r', encoding='utf-8') as f:
            metadata_mapping = json.load(f)
        print(f"ğŸ“‹ ë©”íƒ€ë°ì´í„° íŒŒì¼ ë¡œë“œ ì™„ë£Œ: {len(metadata_mapping)} íŒŒì¼ ì •ë³´ í¬í•¨")
    except Exception as e:
        print(f"âš ï¸ ë©”íƒ€ë°ì´í„° íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")

def get_metadata_for_file(filename: str) -> Dict[str, Any]:
    """íŒŒì¼ ì´ë¦„ì— í•´ë‹¹í•˜ëŠ” ë©”íƒ€ë°ì´í„°ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    base_filename = os.path.basename(filename)
    
    # ë©”íƒ€ë°ì´í„° ë§¤í•‘ì—ì„œ ì°¾ê¸°
    if base_filename in metadata_mapping:
        return metadata_mapping[base_filename]
    
    # íŒŒì¼ëª…ìœ¼ë¡œ ë©”íƒ€ë°ì´í„° ì¶”ì¸¡ (í•„ìš”í•œ ê²½ìš°)
    return {
        "source": base_filename,
        "upload_date": datetime.now().isoformat()
    }

def enhance_metadata(base_metadata: Dict[str, Any], page_num: int) -> Dict[str, Any]:
    """ê¸°ë³¸ ë©”íƒ€ë°ì´í„°ì— í˜ì´ì§€ ì •ë³´ ë“±ì„ ì¶”ê°€í•©ë‹ˆë‹¤."""
    enhanced = base_metadata.copy()
    enhanced["page"] = page_num
    return enhanced

# PDF íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
pdf_dir = args.pdf_dir
pdf_pattern = os.path.join(pdf_dir, "*.pdf")
pdf_files = glob.glob(pdf_pattern)

if not pdf_files:
    print(f"âš ï¸ {pdf_pattern} ê²½ë¡œì— PDF íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    exit(1)

print(f"ğŸ” {len(pdf_files)}ê°œì˜ PDF íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")

# ë©”íƒ€ë°ì´í„° ì…ë ¥ ë„ìš°ë¯¸ í•¨ìˆ˜
def prompt_for_metadata(filename: str) -> Dict[str, Any]:
    """ì‚¬ìš©ìì—ê²Œ ë©”íƒ€ë°ì´í„° ì…ë ¥ì„ ìš”ì²­í•©ë‹ˆë‹¤."""
    print(f"\nğŸ“„ íŒŒì¼: {filename}ì— ëŒ€í•œ ë©”íƒ€ë°ì´í„° ì…ë ¥")
    
    metadata = {
        "source": os.path.basename(filename),
        "upload_date": datetime.now().isoformat()
    }
    
    # ê¸°ë³¸ ë©”íƒ€ë°ì´í„° í•„ë“œ
    fields = [
        ("insurer", "ë³´í—˜ì‚¬ëª… (ì˜ˆ: êµë³´ìƒëª…)"),
        ("product_name", "ìƒí’ˆëª… (ì˜ˆ: í‘œì í•­ì•”ë³´ì¥ë³´í—˜)"),
        ("policy_type", "ì•½ê´€ì¢…ë¥˜ (ì˜ˆ: ì£¼ê³„ì•½/íŠ¹ì•½/ê°±ì‹ í˜•)"),
        ("effective_date", "ì‹œí–‰ì¼ì (YYYY-MM-DD)"),
        ("version", "ë²„ì „ (ì˜ˆ: v1.3)"),
        ("coverage_type", "ë³´ì¥ìœ í˜• (ì˜ˆ: ì•”ë³´í—˜/ìƒí•´ë³´í—˜/ìƒëª…ë³´í—˜)")
    ]
    
    # ê° í•„ë“œ ì…ë ¥ ë°›ê¸°
    for field_name, description in fields:
        value = input(f"{description}: ").strip()
        if value:  # ê°’ì´ ìˆì„ ë•Œë§Œ ì €ì¥
            metadata[field_name] = value
    
    return metadata

# ê° PDF ì²˜ë¦¬
for pdf_path in pdf_files:
    filename = os.path.basename(pdf_path)
    
    # ì´ë¯¸ ë©”íƒ€ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸
    if filename not in metadata_mapping:
        # ì—†ìœ¼ë©´ ì‚¬ìš©ìì—ê²Œ ì…ë ¥ ìš”ì²­
        print(f"\nğŸ†• ìƒˆ íŒŒì¼: {filename}ì— ëŒ€í•œ ë©”íƒ€ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        file_metadata = prompt_for_metadata(pdf_path)
        
        # ë©”íƒ€ë°ì´í„° ë§¤í•‘ì— ì¶”ê°€ (ë‚˜ì¤‘ì— ì €ì¥)
        metadata_mapping[filename] = file_metadata
    else:
        # ìˆìœ¼ë©´ ê¸°ì¡´ ë©”íƒ€ë°ì´í„° ì‚¬ìš©
        file_metadata = metadata_mapping[filename]
        print(f"\nğŸ“‹ {filename}ì— ëŒ€í•œ ë©”íƒ€ë°ì´í„°ë¥¼ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
    
    try:
        # PDF ë¡œë“œ ë° ë¶„í• 
        print(f"ğŸ“– {pdf_path} ë¡œë“œ ì¤‘...")
        loader = PyPDFLoader(pdf_path)
        pages = loader.load_and_split(splitter)
        
        # ê° í˜ì´ì§€ë³„ ë©”íƒ€ë°ì´í„° ê°•í™”
        enhanced_metadata = []
        for i, page in enumerate(pages):
            page_metadata = enhance_metadata(file_metadata, i + 1)
            enhanced_metadata.append(page_metadata)
        
        # Pineconeì— ì—…ë¡œë“œ
        vectorstore.add_texts(
            [p.page_content for p in pages],
            enhanced_metadata
        )
        
        print(f"âœ… {pdf_path} â†’ {len(pages)} chunks ì—…ë¡œë“œ ì™„ë£Œ")
        
        # ë©”íƒ€ë°ì´í„° ì„¸ë¶€ ì •ë³´ ì¶œë ¥
        meta_info = ", ".join([f"{k}: {v}" for k, v in file_metadata.items() if k != "source"])
        print(f"ğŸ“Š ì ìš©ëœ ë©”íƒ€ë°ì´í„°: {meta_info}")
        
    except Exception as e:
        print(f"âŒ {pdf_path} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")

# ì—…ë°ì´íŠ¸ëœ ë©”íƒ€ë°ì´í„° ì €ì¥
if args.metadata:
    try:
        with open(args.metadata, 'w', encoding='utf-8') as f:
            json.dump(metadata_mapping, f, ensure_ascii=False, indent=2)
        print(f"\nğŸ’¾ ë©”íƒ€ë°ì´í„° íŒŒì¼ ì €ì¥ ì™„ë£Œ: {args.metadata}")
    except Exception as e:
        print(f"âš ï¸ ë©”íƒ€ë°ì´í„° íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")

print("\nğŸ‰ ëª¨ë“  ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!") 